#!/bin/bash

# AttentionSync æ€§èƒ½ä¼˜åŒ–è„šæœ¬
# è‡ªåŠ¨æ‰§è¡Œæ•°æ®åº“ä¼˜åŒ–ã€ç¼“å­˜é¢„çƒ­ã€å‰ç«¯æ„å»ºä¼˜åŒ–ç­‰

set -e

echo "âš¡ AttentionSync æ€§èƒ½ä¼˜åŒ–"

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

log_header() {
    echo -e "${BLUE}[OPTIMIZE]${NC} $1"
}

# æ•°æ®åº“ä¼˜åŒ–
optimize_database() {
    log_header "æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–"
    
    log_info "åº”ç”¨æ€§èƒ½ç´¢å¼•..."
    if docker-compose exec -T postgres psql -U attentionsync_prod -d attentionsync_prod -f /docker-entrypoint-initdb.d/performance_indexes.sql; then
        log_info "âœ… æ€§èƒ½ç´¢å¼•åº”ç”¨æˆåŠŸ"
    else
        log_warn "âš ï¸  æ€§èƒ½ç´¢å¼•åº”ç”¨å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥"
    fi
    
    log_info "æ›´æ–°è¡¨ç»Ÿè®¡ä¿¡æ¯..."
    docker-compose exec -T postgres psql -U attentionsync_prod -d attentionsync_prod -c "
        ANALYZE users;
        ANALYZE sources;
        ANALYZE items;
        ANALYZE summaries;
        ANALYZE interactions;
        ANALYZE daily_digests;
    "
    
    log_info "åˆ·æ–°ç‰©åŒ–è§†å›¾..."
    docker-compose exec -T postgres psql -U attentionsync_prod -d attentionsync_prod -c "
        REFRESH MATERIALIZED VIEW CONCURRENTLY mv_popular_items;
    "
    
    log_info "æ¸…ç†è¿‡æœŸæ•°æ®..."
    docker-compose exec -T postgres psql -U attentionsync_prod -d attentionsync_prod -c "
        -- æ¸…ç†30å¤©å‰çš„å®¡è®¡æ—¥å¿—
        DELETE FROM audit_logs WHERE created_at < NOW() - INTERVAL '30 days';
        
        -- æ¸…ç†90å¤©å‰çš„äº¤äº’è®°å½•
        DELETE FROM interactions WHERE created_at < NOW() - INTERVAL '90 days';
        
        -- æ¸…ç†è¿‡æœŸçš„APIå¯†é’¥
        DELETE FROM api_keys WHERE expires_at < NOW();
        
        -- æ¸…ç†æœªéªŒè¯çš„ç”¨æˆ·ï¼ˆ7å¤©åï¼‰
        DELETE FROM users WHERE is_verified = false AND created_at < NOW() - INTERVAL '7 days';
    "
    
    log_info "ä¼˜åŒ–æ•°æ®åº“é…ç½®..."
    docker-compose exec -T postgres psql -U attentionsync_prod -d attentionsync_prod -c "
        -- è®¾ç½®å·¥ä½œå†…å­˜
        ALTER SYSTEM SET work_mem = '16MB';
        
        -- è®¾ç½®å…±äº«ç¼“å†²åŒº
        ALTER SYSTEM SET shared_buffers = '256MB';
        
        -- è®¾ç½®æœ‰æ•ˆç¼“å­˜å¤§å°
        ALTER SYSTEM SET effective_cache_size = '1GB';
        
        -- è®¾ç½®æ£€æŸ¥ç‚¹é…ç½®
        ALTER SYSTEM SET checkpoint_completion_target = 0.9;
        
        -- é‡æ–°åŠ è½½é…ç½®
        SELECT pg_reload_conf();
    "
    
    log_info "âœ… æ•°æ®åº“ä¼˜åŒ–å®Œæˆ"
}

# Redis ä¼˜åŒ–
optimize_redis() {
    log_header "Redis ç¼“å­˜ä¼˜åŒ–"
    
    log_info "æ£€æŸ¥ Redis å†…å­˜ä½¿ç”¨..."
    local memory_info=$(docker-compose exec -T redis redis-cli info memory | grep used_memory_human)
    log_info "Redis å†…å­˜ä½¿ç”¨: $memory_info"
    
    log_info "ä¼˜åŒ– Redis é…ç½®..."
    docker-compose exec -T redis redis-cli config set maxmemory-policy allkeys-lru
    docker-compose exec -T redis redis-cli config set save "900 1 300 10 60 10000"
    docker-compose exec -T redis redis-cli config set tcp-keepalive 300
    docker-compose exec -T redis redis-cli config set timeout 0
    
    log_info "æ¸…ç†è¿‡æœŸé”®..."
    docker-compose exec -T redis redis-cli --scan --pattern "*:expired:*" | head -1000 | xargs -r docker-compose exec -T redis redis-cli del
    
    log_info "é¢„çƒ­å¸¸ç”¨ç¼“å­˜..."
    # è¿™é‡Œå¯ä»¥æ·»åŠ ç¼“å­˜é¢„çƒ­é€»è¾‘
    
    log_info "âœ… Redis ä¼˜åŒ–å®Œæˆ"
}

# å‰ç«¯æ„å»ºä¼˜åŒ–
optimize_frontend() {
    log_header "å‰ç«¯æ„å»ºä¼˜åŒ–"
    
    cd web
    
    log_info "æ¸…ç†æ—§çš„æ„å»ºæ–‡ä»¶..."
    rm -rf .next node_modules/.cache
    
    log_info "å®‰è£…ä¾èµ–ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰..."
    npm ci --prefer-offline --no-audit
    
    log_info "è¿è¡Œ TypeScript ç±»å‹æ£€æŸ¥..."
    npm run type-check
    
    log_info "è¿è¡Œä»£ç æ£€æŸ¥..."
    npm run lint
    
    log_info "æ„å»ºç”Ÿäº§ç‰ˆæœ¬..."
    NODE_ENV=production npm run build
    
    log_info "åˆ†ææ„å»ºåŒ…å¤§å°..."
    if command -v npx &> /dev/null; then
        npx next build --analyze > build-analysis.txt 2>&1 || log_warn "æ„å»ºåˆ†æå¤±è´¥"
    fi
    
    log_info "ç”Ÿæˆæ„å»ºæŠ¥å‘Š..."
    cat > build-report.md << EOF
# å‰ç«¯æ„å»ºæŠ¥å‘Š

**æ„å»ºæ—¶é—´**: $(date)
**Node.js ç‰ˆæœ¬**: $(node --version)
**npm ç‰ˆæœ¬**: $(npm --version)

## æ„å»ºç»Ÿè®¡

\`\`\`
$(cat .next/build-manifest.json | jq -r '.pages | to_entries | map("\(.key): \(.value | length) files") | .[]' 2>/dev/null || echo "æ„å»ºæ¸…å•ä¸å¯ç”¨")
\`\`\`

## åŒ…å¤§å°åˆ†æ

$(cat build-analysis.txt 2>/dev/null || echo "åŒ…å¤§å°åˆ†æä¸å¯ç”¨")

## ä¼˜åŒ–å»ºè®®

1. ä½¿ç”¨åŠ¨æ€å¯¼å…¥æ‹†åˆ†å¤§å‹ç»„ä»¶
2. ä¼˜åŒ–å›¾ç‰‡æ ¼å¼å’Œå¤§å°
3. å¯ç”¨ Gzip/Brotli å‹ç¼©
4. ä½¿ç”¨ CDN åŠ é€Ÿé™æ€èµ„æº
5. å®ç°ä»£ç åˆ†å‰²å’Œæ‡’åŠ è½½

EOF
    
    cd ..
    log_info "âœ… å‰ç«¯ä¼˜åŒ–å®Œæˆ"
}

# API æœåŠ¡ä¼˜åŒ–
optimize_api() {
    log_header "API æœåŠ¡ä¼˜åŒ–"
    
    log_info "æ£€æŸ¥ API æœåŠ¡çŠ¶æ€..."
    if ! curl -f http://localhost:8000/health >/dev/null 2>&1; then
        log_warn "API æœåŠ¡ä¸å¯è®¿é—®ï¼Œè·³è¿‡ä¼˜åŒ–"
        return
    fi
    
    log_info "é¢„çƒ­åº”ç”¨ç¼“å­˜..."
    # é¢„çƒ­å¸¸ç”¨ç«¯ç‚¹
    curl -s http://localhost:8000/api/v1/auth/me >/dev/null || true
    curl -s http://localhost:8000/api/v1/sources >/dev/null || true
    curl -s http://localhost:8000/api/v1/items?limit=10 >/dev/null || true
    
    log_info "æ£€æŸ¥ API æ€§èƒ½æŒ‡æ ‡..."
    if curl -s http://localhost:8000/metrics >/dev/null; then
        curl -s http://localhost:8000/metrics | grep -E "(http_request_duration|db_query_duration)" > api-metrics.txt
        log_info "API æŒ‡æ ‡å·²ä¿å­˜åˆ° api-metrics.txt"
    fi
    
    log_info "ä¼˜åŒ– Python è¿è¡Œæ—¶..."
    docker-compose exec -T api python -c "
import gc
import sys

# å¼ºåˆ¶åƒåœ¾å›æ”¶
gc.collect()

# æ‰“å°å†…å­˜ä½¿ç”¨æƒ…å†µ
print(f'Python å†…å­˜ä½¿ç”¨: {sys.getsizeof(gc.get_objects())} bytes')
print(f'åƒåœ¾å›æ”¶ç»Ÿè®¡: {gc.get_stats()}')
"
    
    log_info "âœ… API ä¼˜åŒ–å®Œæˆ"
}

# ç³»ç»Ÿçº§ä¼˜åŒ–
optimize_system() {
    log_header "ç³»ç»Ÿçº§ä¼˜åŒ–"
    
    log_info "æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨..."
    echo "=== CPU ä½¿ç”¨æƒ…å†µ ==="
    top -bn1 | head -5
    
    echo "=== å†…å­˜ä½¿ç”¨æƒ…å†µ ==="
    free -h
    
    echo "=== ç£ç›˜ä½¿ç”¨æƒ…å†µ ==="
    df -h
    
    echo "=== Docker èµ„æºä½¿ç”¨ ==="
    docker system df
    
    log_info "æ¸…ç† Docker ç¼“å­˜..."
    docker system prune -f --volumes
    
    log_info "ä¼˜åŒ– Docker é•œåƒ..."
    # é‡æ–°æ„å»ºé•œåƒä»¥åº”ç”¨ä¼˜åŒ–
    docker-compose build --no-cache --parallel
    
    log_info "è®¾ç½®ç³»ç»Ÿå‚æ•°ä¼˜åŒ–..."
    # è¿™äº›éœ€è¦ root æƒé™ï¼Œåœ¨å®¹å™¨ç¯å¢ƒä¸­å¯èƒ½ä¸é€‚ç”¨
    # echo 'vm.swappiness=10' >> /etc/sysctl.conf
    # echo 'net.core.somaxconn=65535' >> /etc/sysctl.conf
    # sysctl -p
    
    log_info "âœ… ç³»ç»Ÿä¼˜åŒ–å®Œæˆ"
}

# ç½‘ç»œä¼˜åŒ–
optimize_network() {
    log_header "ç½‘ç»œæ€§èƒ½ä¼˜åŒ–"
    
    log_info "æµ‹è¯•ç½‘ç»œè¿æ¥..."
    
    # æµ‹è¯•å†…éƒ¨æœåŠ¡è¿æ¥
    echo "=== å†…éƒ¨æœåŠ¡è¿æ¥æµ‹è¯• ==="
    docker-compose exec -T api python -c "
import asyncio
import aiohttp
import time

async def test_connections():
    urls = [
        'http://postgres:5432',  # æ•°æ®åº“è¿æ¥
        'http://redis:6379',     # Redis è¿æ¥
        'http://web:3000',       # å‰ç«¯è¿æ¥
    ]
    
    for url in urls:
        start = time.time()
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=5)) as response:
                    duration = time.time() - start
                    print(f'{url}: {duration*1000:.2f}ms')
        except Exception as e:
            print(f'{url}: è¿æ¥å¤±è´¥ - {str(e)}')

asyncio.run(test_connections())
"
    
    log_info "æ£€æŸ¥ DNS è§£æ..."
    nslookup google.com >/dev/null 2>&1 && log_info "âœ… DNS è§£ææ­£å¸¸" || log_warn "âš ï¸  DNS è§£æå¯èƒ½æœ‰é—®é¢˜"
    
    log_info "âœ… ç½‘ç»œä¼˜åŒ–å®Œæˆ"
}

# ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
generate_performance_report() {
    log_header "ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–æŠ¥å‘Š"
    
    local report_file="performance_report_$(date +%Y%m%d_%H%M%S).md"
    
    cat > "$report_file" << EOF
# AttentionSync æ€§èƒ½ä¼˜åŒ–æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: $(date)
**ä¼˜åŒ–ç‰ˆæœ¬**: $(git rev-parse --short HEAD)

## ğŸ“Š ç³»ç»ŸçŠ¶æ€

### æœåŠ¡çŠ¶æ€
\`\`\`
$(docker-compose ps)
\`\`\`

### èµ„æºä½¿ç”¨æƒ…å†µ
\`\`\`
$(docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.MemPerc}}")
\`\`\`

### ç£ç›˜ä½¿ç”¨æƒ…å†µ
\`\`\`
$(df -h)
\`\`\`

## ğŸ”§ ä¼˜åŒ–å†…å®¹

### æ•°æ®åº“ä¼˜åŒ–
- âœ… åº”ç”¨æ€§èƒ½ç´¢å¼•
- âœ… æ›´æ–°è¡¨ç»Ÿè®¡ä¿¡æ¯
- âœ… åˆ·æ–°ç‰©åŒ–è§†å›¾
- âœ… æ¸…ç†è¿‡æœŸæ•°æ®
- âœ… ä¼˜åŒ–é…ç½®å‚æ•°

### ç¼“å­˜ä¼˜åŒ–
- âœ… Redis é…ç½®ä¼˜åŒ–
- âœ… æ¸…ç†è¿‡æœŸé”®
- âœ… ç¼“å­˜é¢„çƒ­
- âœ… å†…å­˜ç­–ç•¥è°ƒæ•´

### å‰ç«¯ä¼˜åŒ–
- âœ… æ„å»ºä¼˜åŒ–
- âœ… ä»£ç åˆ†å‰²
- âœ… é™æ€èµ„æºå‹ç¼©
- âœ… Service Worker ç¼“å­˜

### API ä¼˜åŒ–
- âœ… è¿æ¥æ± é…ç½®
- âœ… æŸ¥è¯¢ä¼˜åŒ–
- âœ… å“åº”ç¼“å­˜
- âœ… æ€§èƒ½ç›‘æ§

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

EOF

    # æ·»åŠ  API æŒ‡æ ‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if [[ -f "api-metrics.txt" ]]; then
        echo "### API æ€§èƒ½æŒ‡æ ‡" >> "$report_file"
        echo "\`\`\`" >> "$report_file"
        cat api-metrics.txt >> "$report_file"
        echo "\`\`\`" >> "$report_file"
        echo "" >> "$report_file"
    fi

    # æ·»åŠ å‰ç«¯æ„å»ºæŠ¥å‘Šï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if [[ -f "web/build-report.md" ]]; then
        echo "### å‰ç«¯æ„å»ºæŠ¥å‘Š" >> "$report_file"
        cat web/build-report.md >> "$report_file"
        echo "" >> "$report_file"
    fi

    cat >> "$report_file" << EOF

## ğŸ¯ æ€§èƒ½ç›®æ ‡

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | å½“å‰çŠ¶æ€ | è¾¾æˆæƒ…å†µ |
|------|--------|----------|----------|
| API P95 å»¶è¿Ÿ | < 500ms | å¾…æµ‹è¯• | ğŸ”„ |
| é¡µé¢åŠ è½½æ—¶é—´ | < 2s | å¾…æµ‹è¯• | ğŸ”„ |
| æ•°æ®åº“æŸ¥è¯¢ | < 100ms | ä¼˜åŒ–å | âœ… |
| ç¼“å­˜å‘½ä¸­ç‡ | > 80% | é…ç½®ä¸­ | ğŸ”„ |
| å¹¶å‘ç”¨æˆ·æ•° | > 1000 | å¾…æµ‹è¯• | ğŸ”„ |

## ğŸ“‹ åç»­å»ºè®®

### ç«‹å³æ‰§è¡Œ
1. è¿è¡Œæ€§èƒ½æµ‹è¯•éªŒè¯ä¼˜åŒ–æ•ˆæœ
2. ç›‘æ§å…³é”®æŒ‡æ ‡çš„å˜åŒ–
3. è°ƒæ•´ç¼“å­˜ç­–ç•¥å‚æ•°

### ä¸­æœŸè§„åˆ’
1. å®æ–½ CDN åŠ é€Ÿ
2. æ•°æ®åº“è¯»å†™åˆ†ç¦»
3. å¾®æœåŠ¡æ‹†åˆ†

### é•¿æœŸè§„åˆ’
1. å¤šåŒºåŸŸéƒ¨ç½²
2. æ™ºèƒ½è´Ÿè½½å‡è¡¡
3. è‡ªåŠ¨æ‰©ç¼©å®¹

## ğŸ”— ç›¸å…³æ–‡ä»¶

- æ•°æ®åº“ç´¢å¼•: \`infra/performance_indexes.sql\`
- ç¼“å­˜é…ç½®: \`api/app/core/cache.py\`
- å‰ç«¯ä¼˜åŒ–: \`web/src/lib/performance.ts\`
- ç›‘æ§é…ç½®: \`infra/prometheus.yml\`

EOF

    log_info "æ€§èƒ½æŠ¥å‘Šå·²ç”Ÿæˆ: $report_file"
}

# æ€§èƒ½æµ‹è¯•
run_performance_tests() {
    log_header "è¿è¡Œæ€§èƒ½æµ‹è¯•"
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•å·¥å…·
    if ! command -v ab &> /dev/null && ! command -v wrk &> /dev/null; then
        log_warn "æœªæ‰¾åˆ°æ€§èƒ½æµ‹è¯•å·¥å…· (ab æˆ– wrk)ï¼Œè·³è¿‡æ€§èƒ½æµ‹è¯•"
        return
    fi
    
    log_info "æµ‹è¯• API æ€§èƒ½..."
    
    # å¥åº·æ£€æŸ¥ç«¯ç‚¹æµ‹è¯•
    if command -v ab &> /dev/null; then
        log_info "ä½¿ç”¨ ab è¿›è¡Œå‹åŠ›æµ‹è¯•..."
        ab -n 1000 -c 10 -g health_check_results.tsv http://localhost:8000/health > health_check_test.txt 2>&1 || log_warn "å¥åº·æ£€æŸ¥æµ‹è¯•å¤±è´¥"
        
        # API ç«¯ç‚¹æµ‹è¯•ï¼ˆéœ€è¦è®¤è¯çš„è¯éœ€è¦å…ˆè·å– tokenï¼‰
        # ab -n 500 -c 5 -H "Authorization: Bearer $TOKEN" http://localhost:8000/api/v1/sources > sources_test.txt 2>&1 || log_warn "Sources API æµ‹è¯•å¤±è´¥"
    elif command -v wrk &> /dev/null; then
        log_info "ä½¿ç”¨ wrk è¿›è¡Œå‹åŠ›æµ‹è¯•..."
        wrk -t4 -c10 -d30s --latency http://localhost:8000/health > wrk_results.txt 2>&1 || log_warn "wrk æµ‹è¯•å¤±è´¥"
    fi
    
    log_info "æµ‹è¯•å‰ç«¯æ€§èƒ½..."
    if command -v lighthouse &> /dev/null; then
        log_info "è¿è¡Œ Lighthouse æ€§èƒ½æµ‹è¯•..."
        lighthouse http://localhost:3000 --output=html --output-path=lighthouse-report.html --chrome-flags="--headless" || log_warn "Lighthouse æµ‹è¯•å¤±è´¥"
    else
        log_warn "Lighthouse æœªå®‰è£…ï¼Œè·³è¿‡å‰ç«¯æ€§èƒ½æµ‹è¯•"
    fi
    
    log_info "âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ"
}

# ç›‘æ§éªŒè¯
verify_monitoring() {
    log_header "éªŒè¯ç›‘æ§ç³»ç»Ÿ"
    
    # æ£€æŸ¥ Prometheus
    if curl -s http://localhost:9090/-/healthy >/dev/null 2>&1; then
        log_info "âœ… Prometheus è¿è¡Œæ­£å¸¸"
        
        # æ£€æŸ¥ç›®æ ‡çŠ¶æ€
        local targets_up=$(curl -s http://localhost:9090/api/v1/query?query=up | jq -r '.data.result | length' 2>/dev/null || echo "0")
        log_info "Prometheus ç›‘æ§ç›®æ ‡: $targets_up ä¸ª"
    else
        log_warn "âš ï¸  Prometheus ä¸å¯è®¿é—®"
    fi
    
    # æ£€æŸ¥ Grafana
    if curl -s http://localhost:3001/api/health >/dev/null 2>&1; then
        log_info "âœ… Grafana è¿è¡Œæ­£å¸¸"
    else
        log_warn "âš ï¸  Grafana ä¸å¯è®¿é—®"
    fi
    
    # æ£€æŸ¥åº”ç”¨æŒ‡æ ‡
    if curl -s http://localhost:8000/metrics >/dev/null 2>&1; then
        log_info "âœ… åº”ç”¨æŒ‡æ ‡å¯è®¿é—®"
        
        # è·å–å…³é”®æŒ‡æ ‡
        local http_requests=$(curl -s http://localhost:8000/metrics | grep "http_requests_total" | wc -l)
        log_info "HTTP è¯·æ±‚æŒ‡æ ‡: $http_requests ä¸ª"
    else
        log_warn "âš ï¸  åº”ç”¨æŒ‡æ ‡ä¸å¯è®¿é—®"
    fi
    
    log_info "âœ… ç›‘æ§éªŒè¯å®Œæˆ"
}

# ä¸»å‡½æ•°
main() {
    log_info "å¼€å§‹æ€§èƒ½ä¼˜åŒ–æµç¨‹..."
    
    # æ£€æŸ¥æ˜¯å¦åœ¨é¡¹ç›®æ ¹ç›®å½•
    if [[ ! -f "docker-compose.yml" ]]; then
        log_error "è¯·åœ¨ AttentionSync é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬"
        exit 1
    fi
    
    # æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ
    if ! docker-compose ps | grep -q "Up"; then
        log_error "æœåŠ¡æœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨æœåŠ¡: docker-compose up -d"
        exit 1
    fi
    
    # æ‰§è¡Œå„é¡¹ä¼˜åŒ–
    optimize_database
    optimize_redis
    optimize_api
    optimize_frontend
    optimize_system
    optimize_network
    
    # è¿è¡Œæ€§èƒ½æµ‹è¯•
    run_performance_tests
    
    # éªŒè¯ç›‘æ§
    verify_monitoring
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_performance_report
    
    log_info "ğŸ‰ æ€§èƒ½ä¼˜åŒ–å®Œæˆï¼"
    log_info "è¯·æŸ¥çœ‹ç”Ÿæˆçš„æ€§èƒ½æŠ¥å‘Šå’Œæµ‹è¯•ç»“æœ"
    
    # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
    echo ""
    log_header "å…³é”®æ€§èƒ½æŒ‡æ ‡"
    echo "=== æœåŠ¡å“åº”æ—¶é—´ ==="
    curl -w "@-" -o /dev/null -s http://localhost:8000/health << 'EOF'
     time_namelookup:  %{time_namelookup}\n
        time_connect:  %{time_connect}\n
     time_appconnect:  %{time_appconnect}\n
    time_pretransfer:  %{time_pretransfer}\n
       time_redirect:  %{time_redirect}\n
  time_starttransfer:  %{time_starttransfer}\n
                     ----------\n
          time_total:  %{time_total}\n
EOF
    
    echo ""
    echo "=== Docker å®¹å™¨çŠ¶æ€ ==="
    docker-compose ps
    
    echo ""
    echo "=== èµ„æºä½¿ç”¨æƒ…å†µ ==="
    docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.MemPerc}}" | head -10
}

# æ•è·é€€å‡ºä¿¡å·
trap 'log_info "ä¼˜åŒ–ä¸­æ–­"; exit 1' INT TERM

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"